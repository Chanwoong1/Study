{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization\n",
    "\n",
    "- Generalizaton\n",
    "- Under-fitting vs over-fitting\n",
    "- Cross validation\n",
    "- Bias-variance tradeoff\n",
    "- Bootstrapping\n",
    "- Bagging and Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation\n",
    "훈련데이터에 대해 학습을 계속 시켜나가면 훈련데이터의 에러는 줄어들지만 어느순간 테스트 데이터에 대한 에러는 늘어나게 된다.\n",
    "훈련데이터에 대한 에러와 테스트 데이터에 대한 에러의 차이를 좁히는것이 일반화의 시작이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation\n",
    "교차검증은 모델에서 훈련 데이터에서 validation 부분을 나누어 훈련 데이터에서 제외시킨 뒤 학습시킨다.\n",
    "그 뒤 validation 데이터를 이용해 하이퍼파라미터를 조정한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias and Variance\n",
    "![](2021-11-20-09-12-06.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapping\n",
    "Bootstrapping은 학습데이터가 100개가 있다면 그 중 몇개를 뽑아 만든 여러개의 모델이 예측하는 공통적인 값과 전체적인 예측값들을 확인할 수 있고, 그것을 통해 최적화를 진행할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging vs Boosting\n",
    "- Bagging\n",
    "    - Multiple models are being trained with bootstrapping\n",
    "\n",
    "- Boosting\n",
    "    - 여러개의 모델을 만들어, 정보를 취합한 뒤 하나의 모델로 만드는 작업.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Gradient Descent Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent Methods\n",
    "- Stochastic gradient descent\n",
    "    - Update with the gradient computed from a single sample.\n",
    "- Mini-batch gradient descent\n",
    "    - Update with the gradient computed from a subset of data.\n",
    "- Batch gradient descent\n",
    "    - Update with the gradient computed from the whole data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent\n",
    "![](2021-11-20-09-30-19.png)\n",
    "Learing rate를 적당히 잡는것이 중요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Momentum\n",
    "![](2021-11-20-09-31-08.png)\n",
    "모멘텀은 한번 흘러가기 시작한 그레디언트를 유지시켜준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adagrad\n",
    "![](2021-11-20-09-32-33.png)\n",
    "parameter가 얼마나 변한지를 계산하여 많이 변한 parameter은 적게 변화시키고 적게 변한 parameter은 많이 변화시킨다.\n",
    "\n",
    "가장 큰 문제는 시간이 지날수록 G(Sum of gradient squares)는 계속해서 커지기때문에 결국에는 G가 무한대로 가게되면 W의 업데이트가 진행되지않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adadelta\n",
    "![](2021-11-20-09-34-57.png)\n",
    "Adadelta의 큰 특징은 learning rate가 없는것. 우리가 바꿀수있는 요소가 많지않기때문에 많이 활용되는 방법은 아니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSprop\n",
    "![](2021-11-20-09-36-13.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adam\n",
    "![](2021-11-20-09-37-49.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularzation\n",
    "- Early stopping\n",
    "- Parameter norm penalty\n",
    "- Data augmentation\n",
    "- Noise robustness\n",
    "- Label smoothing\n",
    "- Dropout\n",
    "- Batch normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early stopping\n",
    "![](2021-11-20-09-40-06.png)\n",
    "교차검증을 통해 validation error와 training error의 차이가 증가하는 시점에 학습을 멈춘다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Norm Penalty\n",
    "![](2021-11-20-09-41-30.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "![](2021-11-20-09-42-00.png)\n",
    "데이터가 적을때는 DL보다 Neural Networks , ML이 효과적이다. \n",
    "\n",
    "Data Augmentation을 통해 데이터를 늘려서 딥러닝을 효과적으로 수행하도록 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise Robustness\n",
    "![](2021-11-20-09-43-36.png)\n",
    "\n",
    "무작위한 노이즈 입력값 혹은 가중치를 추가한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Smooting\n",
    "![](2021-11-20-09-44-29.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout\n",
    "In each forward pass, randomly set some neurons to zero.\n",
    "![](2021-11-20-09-47-47.png)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
