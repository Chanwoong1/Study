{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Dataset\n",
    "\n",
    "28 * 28 * 1 image (784)\n",
    "\n",
    "0 - 9 digits recognition (10 classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "# batch_size : the number of training examples in one forward/backward pass.\n",
    "# The higher the batch size, the more memory space you'll need.\n",
    "batch_size = 100\n",
    "# epoch : one forward pass and one backward pass of all the training examples\n",
    "training_epochs = 15\n",
    "nb_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing data\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# change data shape\n",
    "print(x_train.shape)  # (60000, 28, 28)\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1] * x_train.shape[2])\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1] * x_test.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change result to one-hot encoding\n",
    "# in tf1, one_hot= True in read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "# took care of it, but here we need to manually convert them\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.model = tf.keras.Sequential()\n",
    "# input = 784 (28 * 28)\n",
    "tf.model.add(tf.keras.layers.Dense(units=10, input_dim = 784, activation = 'softmax'))\n",
    "tf.model.compile(loss='categorical_crossentropy', optimizer=tf.optimizers.Adam(0.001), metrics=['accuracy'])\n",
    "tf.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "600/600 [==============================] - 1s 949us/step - loss: 0.6216 - accuracy: 0.8438\n",
      "Epoch 2/15\n",
      "600/600 [==============================] - 1s 885us/step - loss: 0.3457 - accuracy: 0.9053\n",
      "Epoch 3/15\n",
      "600/600 [==============================] - 1s 886us/step - loss: 0.3097 - accuracy: 0.9143\n",
      "Epoch 4/15\n",
      "600/600 [==============================] - 1s 904us/step - loss: 0.2926 - accuracy: 0.9180\n",
      "Epoch 5/15\n",
      "600/600 [==============================] - 1s 899us/step - loss: 0.2821 - accuracy: 0.9211\n",
      "Epoch 6/15\n",
      "600/600 [==============================] - 1s 913us/step - loss: 0.2747 - accuracy: 0.9232\n",
      "Epoch 7/15\n",
      "600/600 [==============================] - 1s 938us/step - loss: 0.2699 - accuracy: 0.9246\n",
      "Epoch 8/15\n",
      "600/600 [==============================] - 1s 949us/step - loss: 0.2653 - accuracy: 0.9259\n",
      "Epoch 9/15\n",
      "600/600 [==============================] - 1s 983us/step - loss: 0.2622 - accuracy: 0.9273\n",
      "Epoch 10/15\n",
      "600/600 [==============================] - 1s 971us/step - loss: 0.2593 - accuracy: 0.9276\n",
      "Epoch 11/15\n",
      "600/600 [==============================] - 1s 977us/step - loss: 0.2566 - accuracy: 0.9288\n",
      "Epoch 12/15\n",
      "600/600 [==============================] - 1s 927us/step - loss: 0.2550 - accuracy: 0.9284\n",
      "Epoch 13/15\n",
      "600/600 [==============================] - 1s 968us/step - loss: 0.2531 - accuracy: 0.9296\n",
      "Epoch 14/15\n",
      "600/600 [==============================] - 1s 903us/step - loss: 0.2514 - accuracy: 0.9306\n",
      "Epoch 15/15\n",
      "600/600 [==============================] - 1s 961us/step - loss: 0.2495 - accuracy: 0.9304\n"
     ]
    }
   ],
   "source": [
    "history = tf.model.fit(x_train, y_train, batch_size=batch_size, epochs=training_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: \n",
      " [[2.0516525e-06 1.8494086e-11 6.9596535e-06 ... 9.9219865e-01\n",
      "  1.9648220e-05 3.3285510e-04]\n",
      " [1.6063759e-04 2.4499609e-06 9.9236065e-01 ... 5.5103704e-18\n",
      "  3.9026596e-05 4.0793608e-14]\n",
      " [1.1797284e-06 9.8376274e-01 9.3271667e-03 ... 4.9295672e-04\n",
      "  2.7350064e-03 1.9280580e-04]\n",
      " ...\n",
      " [8.5527594e-09 9.1804617e-09 3.3498629e-06 ... 8.9250319e-04\n",
      "  4.8019341e-03 1.0288341e-02]\n",
      " [8.2641151e-08 3.0082666e-07 1.6510876e-07 ... 6.5217606e-08\n",
      "  5.0128242e-03 1.0064560e-07]\n",
      " [9.2776281e-07 4.7563383e-14 5.6725941e-05 ... 3.6342728e-13\n",
      "  1.9875555e-08 5.5073012e-11]]\n"
     ]
    }
   ],
   "source": [
    "predictions = tf.model.predict(x_test)\n",
    "print('Prediction: \\n', predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 1s 582us/step - loss: 0.2455 - accuracy: 0.9320\n",
      "Accuracy:  0.9319833517074585\n"
     ]
    }
   ],
   "source": [
    "score = tf.model.evaluate(x_train, y_train)\n",
    "print('Accuracy: ', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
