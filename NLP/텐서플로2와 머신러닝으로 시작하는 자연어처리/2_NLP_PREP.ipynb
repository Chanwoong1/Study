{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow\n",
    "- 데이터 플로 그래프를 통한 풍부한 표현력\n",
    "- 아이디어 테스트에서 서비스 단계까지 이용 가능\n",
    "- 계산 구조와 목표 함수만 정의하면 자동으로 미분 계산을 처리\n",
    "- 파이썬/C++을 지원하며, SWIG를 통해 다양한 언어 지원 가능\n",
    "- 유연성과 확장성\n",
    "\n",
    "## tf.keras.layers\n",
    "\n",
    "### tf.keras.layers.Dense\n",
    "Dense란 신경망 구조의 가장 기본적인 형태를 의미\n",
    "\n",
    "아래의 수식을 만족하는 기본적인 신경망 형태의 층을 만드는 함수\n",
    "\n",
    "$$ y = f(Wx + b) $$\n",
    "\n",
    "위의 수식에서 x와 b는 각각 입력 벡터, 편향 벡터이며 W는 가중치 행렬이 된다. 즉, 가중치와 입력 벡터를 곱한 후 편향을 더해준다. 그리고 그 값에 f라는 활성화 함수를 적용하는 구조다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import tensorflow as tf\n",
    "W = tf.Variable(tf.random.uniform([5, 10], -1.0, 1.0))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "y = tf.matmul(W, x) + b\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위와 같이 모든 변수들을 선언하고 직접 곱하고, 더해야한다. 하지만 텐서플로의 Dense를 이용하면 한 줄로 위의 코드를 작성할 수 있다. 이 경우 내부적으로 변수를 생성하고 연산을 진행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense를 사용하려면 우선 객체를 생성해야 한다.\n",
    "# dense = tf.keras.layers.Dense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dense 층을 만들 때 여러 인자를 통해 옵션을 정할 수 있다. 다음과 같은 인자들이 있다.\n",
    "\n",
    "- units : 출력 값의 크기, integer 혹은 long 형태\n",
    "- activation : 활성화 함수\n",
    "- use_bias : 편향(b)를 사용할지 여부, Boolean\n",
    "- kernel_initializer : 가중치(W) 초기화 함수\n",
    "- bias_initializer : 편향 초기화 함수\n",
    "- kernel_regularizer : 가중치 정규화 방법\n",
    "- bias_regularizer : 편향 정규화 방법\n",
    "- activity_regularizer : 출력 값 정규화 방법\n",
    "- kernel_constraint : Optimizer에 의해 업데이트 된 이후 가중치에 적용되는 부가적인 제약함수\n",
    "- bias_constraint : Optimizer에 의해 업데이트 된 이후 편향에 적용되는 부가적인 제약함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = (20, 1)\n",
    "CONV_INPUT_SIZE = (1, 28, 28)\n",
    "IS_TRAINING = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense Layer\n",
    "inputs = tf.keras.layers.Input(shape = INPUT_SIZE)\n",
    "output = tf.keras.layers.Dense(units = 10, activation = tf.nn.sigmoid)(inputs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense Layer with 1 hidden layer\n",
    "inputs = tf.keras.layers.Input(shape = INPUT_SIZE)\n",
    "hidden = tf.keras.layers.Dense(units = 10, activation = tf.nn.sigmoid)(inputs)\n",
    "output = tf.keras.layers.Dense(units = 2, activation = tf.nn.sigmoid)(hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.keras.layers.Dropout\n",
    "신경망 모델을 만들 때 생기는 여러 문제점 중 대표적인 문제점은 과적합이다. 과적합 문제는 정규화 방법을 사용해서 해결하는데, 그중 가장 대표적인 방법이 드롭아웃이다.\n",
    "\n",
    "- rate : 드롭아웃을 적용할 확률지정한다. 예를들어 dropout = 0.2라면 전체 입력값 중 20%를 0으로 만든다.\n",
    "\n",
    "- noise_shape : 정수형의 1D-tensor 값을 받는다. 여기서 받은 값은 shape를 뜻하며, 이 값을 지정함으로써 특정 값만 드롭아웃을 적용할 수 있다. 예를 들면 입력값이 이미지일 때 noise_shape를 지정하면 특정 채널에만 드롭아웃을 적용할 수 있다.\n",
    "\n",
    "- seed : 드롭아웃의 경우 지정된 확률 값을 바탕으로 무작위로 드롭아웃을 적용하는데, 이것은 임의의 선택을 위한 시드 값을 의미한다. seed값은 정수형이며, 같은 seed 값을 가지는 드롭아웃의 경우 동일한 드롭아웃 결과를 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropout\n",
    "inputs = tf.keras.layers.Input(shape = INPUT_SIZE)\n",
    "dropout = tf.keras.layers.Dropout(rate = 0.5)(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense Layer with 1 hidden layer and dropout\n",
    "inputs = tf.keras.layers.Input(shape = INPUT_SIZE)\n",
    "dropout = tf.keras.layers.Dropout(rate = 0.2)(inputs)\n",
    "hidden = tf.keras.layers.Dense(units = 10, activation = tf.nn.sigmoid)(dropout)\n",
    "output = tf.keras.layers.Dense(units = 2, activation = tf.nn.sigmoid)(hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.keras.Conv1D\n",
    "합성곱 연산 중 Conv1D는 한 방향(가로)로만 연산을 진행하며, 출력값은 1-D Array로 출력된다.\n",
    "\n",
    "자연어 처리 분야에서 사용하는 합성곱의 경우 각 단어 벡터의 차원 전체에 대해 필터를 적용시키기 위해 주로 Conv1D를 사용한다. 이제 이 Conv1D를 사용하는 방법을 알아보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution layer\n",
    "inputs = tf.keras.layers.Input(shape = INPUT_SIZE)\n",
    "conv = tf.keras.layers.Conv1D(\n",
    "         filters=10,\n",
    "         kernel_size=3,\n",
    "         padding='same',\n",
    "         activation=tf.nn.relu)(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution layer with dropout\n",
    "inputs = tf.keras.layers.Input(shape = INPUT_SIZE)\n",
    "dropout = tf.keras.layers.Dropout(rate=0.2)(inputs)\n",
    "conv = tf.keras.layers.Conv1D(\n",
    "         filters=10,\n",
    "         kernel_size=3,\n",
    "         padding='same',\n",
    "         activation=tf.nn.relu)(dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input -> Dropout -> Convolutional layer -> MaxPooling \n",
    "# -> Dense layer with 1 hidden layer -> Output\n",
    "inputs = tf.keras.layers.Input(shape = INPUT_SIZE)\n",
    "dropout = tf.keras.layers.Dropout(rate = 0.2)(inputs)\n",
    "conv = tf.keras.layers.Conv1D(\n",
    "         filters=10,\n",
    "         kernel_size=3,\n",
    "         padding='same',\n",
    "         activation=tf.nn.relu)(dropout)\n",
    "# max_pool : 피처 맵의 크기를 줄이거나 주요한 특징을 뽑아내기 위해 합성곱 이후에 적용되는 기법\n",
    "max_pool = tf.keras.layers.MaxPool1D(pool_size = 3, padding = 'same')(conv)\n",
    "flatten = tf.keras.layers.Flatten()(max_pool)\n",
    "hidden = tf.keras.layers.Dense(units = 50, activation = tf.nn.relu)(flatten)\n",
    "output = tf.keras.layers.Dense(units = 10, activation = tf.nn.softmax)(hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow 2.0\n",
    "\n",
    "모델 구축\n",
    "\n",
    "텐서플로 2.0은 케라스를 활용해 모델을 구축하고 학습하는 것을 권장한다. 케라스 API는 고수준 API로 사용하기 간편하며 매우 유연하고 높은 성능을 보여준다. 케라스를 활용해 모델을 구축하는 방법을 다음과 같다.\n",
    "- Sequential API\n",
    "- Functional API\n",
    "- Functional/Sequential API\n",
    "    - Custom Layers\n",
    "- Subclassing(Custom Model)\n",
    "\n",
    "### Sequential API\n",
    "케라스를 활용해 모델을 구축할 수 있는 가장 간단한 형태의 API이다. 이 모듈을 이용하면 간단한 순차적인 레이어의 스택을 구현할 수 있다. 아래와 같은 방법을 통해 간단한 형태의 완전 연결 계층(fully-connected layer)를 구현할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Dense(64, activation = 'relu'))\n",
    "model.add(layers.Dense(64, activation = 'relu'))\n",
    "model.add(layers.Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 처럼 인스턴스를 생성한 후 해당 인스턴스에 여러 레이어를 순차적으로 더하기만 하면 모델이 완성된다. 이렇게 만든 모델을 입력값을 더한 순서에 맞게 레이어들을 통화시킨 후 최종 출력값을 뽑아오게 된다. Sequential 모듈의 경우 위와 같이 구현 자체가 매우 간단하다는 사실을 알 수 있다. 간단한 만큼 여러 제약이 존재한다.\n",
    "\n",
    "### Functional API\n",
    "Sequential 모듈은 다음과 같은 모델 구조일 경우 사용하기 어려울 수 있다.\n",
    "- 다중 입력값 모델(Multi-input models)\n",
    "- 다중 출력값 모델(Multi-output models)\n",
    "- 공유 층을 활용하는 모델(Models with shared layers)\n",
    "- 데이터 흐름이 순차적이지 않은 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
